{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tom Bliss\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import string\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "# fix for XGBoost errors\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's read in the dataset and take a initial look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('training_set.csv',\n",
    "                       encoding = 'latin-1',\n",
    "                       parse_dates = ['Created'])\n",
    "\n",
    "df_hold = pd.read_csv('holdout_set.csv',\n",
    "                      encoding = 'latin-1',\n",
    "                      parse_dates = ['Created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('Engagements', axis = 1)\n",
    "X['data_type'] = \"training\"\n",
    "df_hold['data_type'] = \"hold\"\n",
    "X = X.append(df_hold.drop('Engagements', axis = 1))\n",
    "\n",
    "Y = df_train['Engagements']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create more features from our dataset mainly to capture time effect/seasonality and also use the text/captions from the posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series - Month Seasonality with Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing this to be able to put this into linear regression\n",
    "X['month'] = X.Created.apply(lambda x: x.month) #seasonal term\n",
    "X['year_month'] = X.Created.apply(lambda x: x.month + x.year * 12) #trend term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series - Hourly with day of Week and Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing this to be able to put this into linear regression\n",
    "X['hour'] = X.Created.apply(lambda x: x.hour) #seasonal term\n",
    "X['weekend'] = X.Created.apply(lambda x: int(x.dayofweek >= 5)) #seasonal term\n",
    "X['weekend_hour_interaction'] = X.Created.apply(lambda x: int(x.dayofweek >= 5) * x.hour) #seasonal term\n",
    "X['weekday_hour_interaction'] = X.Created.apply(lambda x: int(x.dayofweek < 5) * x.hour) #seasonal term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding features\n",
    "X['day_of_week'] = X.Created.apply(lambda x: x.dayofweek)\n",
    "X = pd.get_dummies(X, columns = [\"day_of_week\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###just one hot encoding everything (not commented out)\n",
    "X = pd.get_dummies(X, columns = ['hour', 'weekend', 'weekend_hour_interaction', 'weekday_hour_interaction', 'month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Features from text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling NA with empty text\n",
    "X.Description.fillna(\"\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial bag-of-words method feature engineering\n",
    "\n",
    "X['containsLink'] = X.Description.str.contains('.http').astype(float)\n",
    "X['exclamationPointCount'] =X.Description.str.count('!').astype(float)\n",
    "X['questionMarkCount'] = X.Description.str.count('\\?').astype(float)\n",
    "X['doubleQuotationMarkCount'] = X.Description.str.count('\\\"').astype(float)\n",
    "X['singleQuoteMarkCount'] = X.Description.str.count('\\'').astype(float)\n",
    "X['commaMarkCount'] = X.Description.str.count(',').astype(float)\n",
    "X['collinCount'] = X.Description.str.count(':').astype(float)\n",
    "X['semiCollinCount'] = X.Description.str.count(';').astype(float)\n",
    "X['percentMarkCount'] = X.Description.str.count('%').astype(float)\n",
    "X['dollarSignCount'] = X.Description.str.count('$').astype(float)\n",
    "X['hashCount'] = X.Description.str.count('#').astype(float)\n",
    "X['starCount'] = X.Description.str.count('\\*').astype(float)\n",
    "X['atCount'] = X.Description.str.count('@').astype(float)\n",
    "X['percentCapital'] = (X.Description.str.findall(r'[A-Z]').str.len().fillna(0)/X.Description.str.len().fillna(1)).fillna(0)\n",
    "X['percentlowercase'] = (X.Description.str.findall(r'[a-z]').str.len().fillna(0)/X.Description.str.len().fillna(1)).fillna(0)\n",
    "X['percentnumbers'] = (X.Description.str.findall(r'[0-9]').str.len().fillna(0)/X.Description.str.len().fillna(1)).fillna(0)\n",
    "X['percentother'] = (1 - X['percentCapital'] - X['percentlowercase'] - X['percentnumbers']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use word2vec from Google News / Twitter \n",
    "w = models.KeyedVectors.load_word2vec_format(\n",
    "    'GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a word2vec model to extract meaning from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts = [[token for token in doc.translate(str.maketrans('', '', string.punctuation)).lower().split()]\n",
    "               for doc in (X['Description']).astype(str)]\n",
    "\n",
    "texts_final = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    doc_final = []\n",
    "    for j in range(len(texts[i])):\n",
    "            if texts[i][j] in w:\n",
    "                doc_final.append(texts[i][j])    \n",
    "    if len(doc_final) < 1:\n",
    "        texts_final.append(['NA'])\n",
    "    else:\n",
    "        texts_final.append(doc_final)\n",
    "        \n",
    "embedding = np.vstack([np.mean(w[doc], axis=0) for doc in texts_final])\n",
    "\n",
    "for i in range(len(embedding[0])):\n",
    "    X['embedding_' + str(i)] = embedding[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummies for type column\n",
    "X = pd.get_dummies(X, columns = [\"Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing train test split on training data an then using tfidf vectorizor to extract each word in description indivdually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.loc[X.data_type == \"training\"].drop(\"data_type\", axis = 1),\n",
    "                                                    Y,\n",
    "                                                    random_state = 23)\n",
    "\n",
    "\n",
    "#count vectorizor\n",
    "vect = TfidfVectorizer()\n",
    "X_train_sparse = vect.fit_transform(X_train.Description)\n",
    "X_test_sparse = vect.transform(X_test.Description)\n",
    "\n",
    "X_train.drop(['Description', \"Created\"], axis = 1, inplace = True)\n",
    "X_test.drop(['Description', \"Created\"], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "for feature in X_train.columns:\n",
    "    X_train_sparse = hstack((X_train_sparse, np.array(X_train[feature]).reshape(-1,1)))\n",
    "    X_test_sparse = hstack((X_test_sparse, np.array(X_test[feature]).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting / Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our model selection, we will use MAPE as our scoring system and look over both linear (LR, Lasso, etc.) and non-linear models (RandomForest, XGB). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# custom MAPE scorer for sklearn\n",
    "def MAPE(y, y_pred, **kwargs):\n",
    "    return sum(abs((y - y_pred) / y))/len(y)\n",
    "\n",
    "mape_scorer = make_scorer(MAPE, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "MAPE Scores:  [0.14569288 0.13411596 0.12789666 0.13918109 0.14467435]\n",
      "Mean MAPE:  0.13831218821204724\n",
      "\n",
      "===========================\n",
      "\n",
      "Ridge\n",
      "MAPE Scores:  [0.32576616 0.32560614 0.32537874 0.33895551 0.32731159]\n",
      "Mean MAPE:  0.32860362746736504\n",
      "\n",
      "===========================\n",
      "\n",
      "Lasso\n",
      "MAPE Scores:  [0.06699133 0.07185476 0.068208   0.06922346 0.07171168]\n",
      "Mean MAPE:  0.06959784682865824\n",
      "\n",
      "===========================\n",
      "\n",
      "RandomForestRegressor\n",
      "MAPE Scores:  [0.05503405 0.0530034  0.05087014 0.05329416 0.05509563]\n",
      "Mean MAPE:  0.05345947651825219\n",
      "\n",
      "===========================\n",
      "\n",
      "XGBRegressor\n",
      "MAPE Scores:  [0.05108    0.05242051 0.04484114 0.04936731 0.05017491]\n",
      "Mean MAPE:  0.04957677223406316\n",
      "\n",
      "===========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [LinearRegression(),\n",
    "          Ridge(),\n",
    "          Lasso(),\n",
    "          RandomForestRegressor(),\n",
    "          XGBRegressor()]\n",
    "\n",
    "for mdl in models: \n",
    "    print(type(mdl).__name__)\n",
    "    score = cross_val_score(mdl, X_train_sparse, y_train, \n",
    "                          n_jobs=-1, scoring=mape_scorer, cv=5)\n",
    "    \n",
    "    print(\"MAPE Scores: \", score)\n",
    "    print(\"Mean MAPE: \", np.mean(score))\n",
    "    print(\"\\n===========================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best performing model is XGBRegressor, but Lasso does relatively well, which we can use if we need a more interpretable/simpler model. For our case, let's just use XGBRegressor since we care more of predictive power. Let's tune the XGBoost model for our problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth =  5\n",
      "n_estimators =  100\n",
      "MAPE Scores:  [0.03753432 0.03668317 0.03217733 0.03619439 0.0345801 ]\n",
      "Mean MAPE:  0.0354338620235566\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  7\n",
      "n_estimators =  100\n",
      "MAPE Scores:  [0.03298479 0.03321254 0.02919338 0.03140563 0.03143909]\n",
      "Mean MAPE:  0.031647084619057894\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  9\n",
      "n_estimators =  100\n",
      "MAPE Scores:  [0.03338576 0.03195707 0.03014845 0.03137227 0.03115694]\n",
      "Mean MAPE:  0.03160409894524039\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  11\n",
      "n_estimators =  100\n",
      "MAPE Scores:  [0.03407896 0.03397291 0.03155152 0.03272708 0.0326472 ]\n",
      "Mean MAPE:  0.03299553316992165\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  13\n",
      "n_estimators =  100\n",
      "MAPE Scores:  [0.0355577  0.03527928 0.03346074 0.03387516 0.03440251]\n",
      "Mean MAPE:  0.034515078730822255\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  15\n",
      "n_estimators =  100\n",
      "MAPE Scores:  [0.0366217  0.03572249 0.03467205 0.03508342 0.0357137 ]\n",
      "Mean MAPE:  0.03556267314210072\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  5\n",
      "n_estimators =  150\n",
      "MAPE Scores:  [0.03273732 0.03314394 0.02814703 0.03168077 0.03017431]\n",
      "Mean MAPE:  0.031176673024719485\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  7\n",
      "n_estimators =  150\n",
      "MAPE Scores:  [0.03120957 0.03127116 0.02741512 0.02951633 0.02938761]\n",
      "Mean MAPE:  0.029759957841954288\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  9\n",
      "n_estimators =  150\n",
      "MAPE Scores:  [0.03246833 0.0310071  0.02910967 0.0303953  0.03024972]\n",
      "Mean MAPE:  0.030646022775220626\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  11\n",
      "n_estimators =  150\n",
      "MAPE Scores:  [0.03370636 0.03348362 0.03114245 0.0322921  0.03224213]\n",
      "Mean MAPE:  0.03257333263711617\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  13\n",
      "n_estimators =  150\n",
      "MAPE Scores:  [0.03532055 0.0350259  0.03326389 0.033668   0.03417877]\n",
      "Mean MAPE:  0.03429141960174055\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  15\n",
      "n_estimators =  150\n",
      "MAPE Scores:  [0.03647838 0.03555382 0.0345319  0.03493423 0.03554488]\n",
      "Mean MAPE:  0.03540864128937504\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  5\n",
      "n_estimators =  250\n",
      "MAPE Scores:  [0.03014042 0.03024248 0.02576702 0.02917046 0.02768346]\n",
      "Mean MAPE:  0.02860076761628842\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  7\n",
      "n_estimators =  250\n",
      "MAPE Scores:  [0.03010386 0.03026759 0.02656646 0.02836658 0.02850237]\n",
      "Mean MAPE:  0.02876137250361705\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  9\n",
      "n_estimators =  250\n",
      "MAPE Scores:  [0.03212022 0.03047441 0.02868456 0.03006491 0.02985034]\n",
      "Mean MAPE:  0.030238887106155504\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  11\n",
      "n_estimators =  250\n",
      "MAPE Scores:  [0.03362613 0.03328659 0.03098888 0.03214014 0.03209447]\n",
      "Mean MAPE:  0.032427240872672146\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  13\n",
      "n_estimators =  250\n",
      "MAPE Scores:  [0.03521493 0.03493456 0.03319439 0.03359122 0.03408531]\n",
      "Mean MAPE:  0.034204082124828596\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  15\n",
      "n_estimators =  250\n",
      "MAPE Scores:  [0.03643473 0.03548925 0.03448966 0.03488459 0.03550603]\n",
      "Mean MAPE:  0.03536085249749643\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  5\n",
      "n_estimators =  300\n",
      "MAPE Scores:  [0.02957207 0.02969764 0.02535064 0.02860717 0.0271284 ]\n",
      "Mean MAPE:  0.028071185503950317\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  7\n",
      "n_estimators =  300\n",
      "MAPE Scores:  [0.02992952 0.03005855 0.02641717 0.02811334 0.02831769]\n",
      "Mean MAPE:  0.0285672538951611\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  9\n",
      "n_estimators =  300\n",
      "MAPE Scores:  [0.03206437 0.030368   0.02861596 0.03000333 0.02978999]\n",
      "Mean MAPE:  0.03016833142153926\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  11\n",
      "n_estimators =  300\n",
      "MAPE Scores:  [0.03360027 0.03325082 0.03095895 0.03210522 0.03206686]\n",
      "Mean MAPE:  0.032396426911780074\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  13\n",
      "n_estimators =  300\n",
      "MAPE Scores:  [0.03520866 0.03491862 0.03317374 0.03357068 0.03408096]\n",
      "Mean MAPE:  0.03419053344946678\n",
      "\n",
      "===========================\n",
      "\n",
      "max_depth =  15\n",
      "n_estimators =  300\n",
      "MAPE Scores:  [0.03642876 0.03547473 0.03448666 0.03487124 0.03550029]\n",
      "Mean MAPE:  0.03535233697751651\n",
      "\n",
      "===========================\n",
      "\n",
      "Best Mean CV Score: 0.028 when max_depth = 5.000, when n_estimators = 300.000, and when min_child_weight = 10.000\n"
     ]
    }
   ],
   "source": [
    "best_score = 1\n",
    "best_max_depth = 0\n",
    "best_n_estimators = 0\n",
    "\n",
    "for n_estimators_param in [100, 150, 250, 300]:\n",
    "    for max_depth_param in [5, 7, 9, 11, 13, 15]:\n",
    "            model = XGBRegressor(max_depth = max_depth_param,\n",
    "                                 n_estimators = n_estimators_param)\n",
    "            score = cross_val_score(model, X_train_sparse, y_train, \n",
    "                          n_jobs=-1, scoring=mape_scorer, cv=5)\n",
    "        \n",
    "        \n",
    "            print(\"max_depth = \", max_depth_param)\n",
    "            print(\"n_estimators = \", n_estimators_param)\n",
    "            print(\"MAPE Scores: \", score)\n",
    "            print(\"Mean MAPE: \", np.mean(score))\n",
    "            print(\"\\n===========================\\n\")\n",
    "    \n",
    "            if np.mean(score) < best_score:\n",
    "                best_score = np.mean(score)\n",
    "                best_max_depth = max_depth_param\n",
    "                best_n_estimators = n_estimators_param\n",
    "\n",
    "\n",
    "\n",
    "print('Best Mean CV Score: {0:.3f}'\n",
    "      .format(best_score)\n",
    "      + ' when max_depth = {0:.3f}'\n",
    "      .format(best_max_depth)\n",
    "      + ', when n_estimators = {0:.3f}'\n",
    "      .format(best_n_estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets evaluate our model on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:08] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "MAPE:  2.577589318192902 %\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth = best_max_depth, n_estimators = best_n_estimators)\n",
    "model = xgb.fit(X_train_sparse, y_train, verbose=True)\n",
    "y_pred = xgb.predict(X_test_sparse)\n",
    "print(\"MAPE: \", MAPE(y_test, y_pred)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on Holdout Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the best model above, we now predict the holdout set for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.01262200080591515\n"
     ]
    }
   ],
   "source": [
    "#refitting tfidf with full data set\n",
    "X_hold = X.loc[X.data_type == \"hold\"].drop(\"data_type\", axis = 1)\n",
    "\n",
    "X_train_total = X.loc[X.data_type == \"training\"].drop(\"data_type\", axis = 1)\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "X_train_total_sparse = vect.fit_transform(X_train_total.Description)\n",
    "X_hold_sparse = vect.transform(X_hold.Description)\n",
    "\n",
    "X_hold.drop(['Description', \"Created\"], axis = 1, inplace = True)\n",
    "\n",
    "for feature in X_train.columns:\n",
    "    X_train_total_sparse = hstack((X_train_total_sparse, np.array(X_train_total[feature]).reshape(-1,1)))\n",
    "    X_hold_sparse = hstack((X_hold_sparse, np.array(X_hold[feature]).reshape(-1,1)))\n",
    "\n",
    "#refitting xgb on full data set \n",
    "model = xgb.fit(X_train_total_sparse, Y)\n",
    "\n",
    "#double checking this was done correctly\n",
    "print(\"Training error: \", sum(abs((Y - model.predict(X_train_total_sparse)) / Y))/len(Y))\n",
    "\n",
    "\n",
    "df_hold.drop('data_type', axis = 1, inplace = True)\n",
    "df_hold.Engagements = model.predict(X_hold_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hold.Engagements = model.predict(X_hold_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hold.to_csv(\"holdout_set_Columbia3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
