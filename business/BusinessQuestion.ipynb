{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import string\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "# fix for XGBoost errors\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's read in the dataset and take a initial look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('training_set.csv',\n",
    "                       encoding = 'latin-1',\n",
    "                       parse_dates = ['Created'])\n",
    "\n",
    "df_hold = pd.read_csv('holdout_set.csv',\n",
    "                      encoding = 'latin-1',\n",
    "                      parse_dates = ['Created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('Engagements', axis = 1)\n",
    "X['data_type'] = \"training\"\n",
    "df_hold['data_type'] = \"hold\"\n",
    "X = X.append(df_hold.drop('Engagements', axis = 1))\n",
    "\n",
    "Y = df_train['Engagements']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create more features from our dataset mainly to capture time effect/seasonality and also use the text/captions from the posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series - Month Seasonality with Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing this to be able to put this into linear regression\n",
    "X['month'] = X.Created.apply(lambda x: x.month) #seasonal term\n",
    "X['year_month'] = X.Created.apply(lambda x: x.month + x.year * 12) #trend term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series - Hourly with day of Week and Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing this to be able to put this into linear regression\n",
    "X['hour'] = X.Created.apply(lambda x: x.hour) #seasonal term\n",
    "X['weekend'] = X.Created.apply(lambda x: int(x.dayofweek >= 5)) #seasonal term\n",
    "X['weekend_hour_interaction'] = X.Created.apply(lambda x: int(x.dayofweek >= 5) * x.hour) #seasonal term\n",
    "X['weekday_hour_interaction'] = X.Created.apply(lambda x: int(x.dayofweek < 5) * x.hour) #seasonal term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding features\n",
    "X['day_of_week'] = X.Created.apply(lambda x: x.dayofweek)\n",
    "X = pd.get_dummies(X, columns = [\"day_of_week\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###just one hot encoding everything (not commented out)\n",
    "X = pd.get_dummies(X, columns = ['hour', 'weekend', 'weekend_hour_interaction', 'weekday_hour_interaction', 'month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Features from text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling NA with empty text\n",
    "X.Description.fillna(\"\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial bag-of-words method feature engineering\n",
    "\n",
    "X['containsLink'] = X.Description.str.contains('.http').astype(float)\n",
    "X['exclamationPointCount'] =X.Description.str.count('!').astype(float)\n",
    "X['questionMarkCount'] = X.Description.str.count('\\?').astype(float)\n",
    "X['doubleQuotationMarkCount'] = X.Description.str.count('\\\"').astype(float)\n",
    "X['singleQuoteMarkCount'] = X.Description.str.count('\\'').astype(float)\n",
    "X['commaMarkCount'] = X.Description.str.count(',').astype(float)\n",
    "X['collinCount'] = X.Description.str.count(':').astype(float)\n",
    "X['semiCollinCount'] = X.Description.str.count(';').astype(float)\n",
    "X['percentMarkCount'] = X.Description.str.count('%').astype(float)\n",
    "X['dollarSignCount'] = X.Description.str.count('$').astype(float)\n",
    "X['hashCount'] = X.Description.str.count('#').astype(float)\n",
    "X['starCount'] = X.Description.str.count('\\*').astype(float)\n",
    "X['atCount'] = X.Description.str.count('@').astype(float)\n",
    "X['percentCapital'] = (X.Description.str.findall(r'[A-Z]').str.len().fillna(0)/X.Description.str.len().fillna(1)).fillna(0)\n",
    "X['percentlowercase'] = (X.Description.str.findall(r'[a-z]').str.len().fillna(0)/X.Description.str.len().fillna(1)).fillna(0)\n",
    "X['percentnumbers'] = (X.Description.str.findall(r'[0-9]').str.len().fillna(0)/X.Description.str.len().fillna(1)).fillna(0)\n",
    "X['percentother'] = (1 - X['percentCapital'] - X['percentlowercase'] - X['percentnumbers']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use word2vec from Google News / Twitter \n",
    "w = models.KeyedVectors.load_word2vec_format(\n",
    "    'GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Explain Here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts = [[token for token in doc.translate(str.maketrans('', '', string.punctuation)).lower().split()]\n",
    "               for doc in (X['Description']).astype(str)]\n",
    "\n",
    "texts_final = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    doc_final = []\n",
    "    for j in range(len(texts[i])):\n",
    "            if texts[i][j] in w:\n",
    "                doc_final.append(texts[i][j])    \n",
    "    if len(doc_final) < 1:\n",
    "        texts_final.append(['NA'])\n",
    "    else:\n",
    "        texts_final.append(doc_final)\n",
    "        \n",
    "embedding = np.vstack([np.mean(w[doc], axis=0) for doc in texts_final])\n",
    "\n",
    "for i in range(len(embedding[0])):\n",
    "    X['embedding_' + str(i)] = embedding[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummies for type column\n",
    "X = pd.get_dummies(X, columns = [\"Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.loc[X.data_type == \"training\"].drop(\"data_type\", axis = 1),\n",
    "                                                    Y,\n",
    "                                                    random_state = 23)\n",
    "\n",
    "\n",
    "#count vectorizor\n",
    "vect = TfidfVectorizer()\n",
    "X_train_sparse = vect.fit_transform(X_train.Description)\n",
    "X_test_sparse = vect.transform(X_test.Description)\n",
    "\n",
    "X_train.drop(['Description', \"Created\"], axis = 1, inplace = True)\n",
    "X_test.drop(['Description', \"Created\"], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "for feature in X_train.columns:\n",
    "    X_train_sparse = hstack((X_train_sparse, np.array(X_train[feature]).reshape(-1,1)))\n",
    "    X_test_sparse = hstack((X_test_sparse, np.array(X_test[feature]).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting / Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our model selection, we will use MAPE as our scoring system and look over both linear (LR, Lasso, etc.) and non-linear models (RandomForest, XGB). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# custom MAPE scorer for sklearn\n",
    "def MAPE(y, y_pred, **kwargs):\n",
    "    return sum(abs((y - y_pred) / y))/len(y)\n",
    "\n",
    "mape_scorer = make_scorer(MAPE, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "MAPE Scores:  [0.14578238 0.13417232 0.12814485 0.1390726  0.14465127]\n",
      "Mean MAPE:  0.13836468461528803\n",
      "\n",
      "===========================\n",
      "\n",
      "Ridge\n",
      "MAPE Scores:  [0.32576615 0.32560614 0.32537882 0.33895547 0.32731153]\n",
      "Mean MAPE:  0.32860362232089513\n",
      "\n",
      "===========================\n",
      "\n",
      "Lasso\n",
      "MAPE Scores:  [0.06699134 0.07185016 0.06820862 0.06919705 0.0717084 ]\n",
      "Mean MAPE:  0.06959111156982353\n",
      "\n",
      "===========================\n",
      "\n",
      "RandomForestRegressor\n",
      "MAPE Scores:  [0.05341027 0.05438591 0.0521782  0.05324786 0.05483808]\n",
      "Mean MAPE:  0.05361206496980936\n",
      "\n",
      "===========================\n",
      "\n",
      "XGBRegressor\n",
      "MAPE Scores:  [0.0513494  0.05132419 0.04435567 0.04977749 0.04999716]\n",
      "Mean MAPE:  0.04936078119842423\n",
      "\n",
      "===========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [LinearRegression(),\n",
    "          Ridge(),\n",
    "          Lasso(),\n",
    "          RandomForestRegressor(),\n",
    "          XGBRegressor()\n",
    "         ]\n",
    "\n",
    "for mdl in models: \n",
    "    print(type(mdl).__name__)\n",
    "    score = cross_val_score(mdl, X_train_sparse, y_train, \n",
    "                          n_jobs=-1, scoring=mape_scorer, cv=5)\n",
    "    \n",
    "    print(\"MAPE Scores: \", score)\n",
    "    print(\"Mean MAPE: \", np.mean(score))\n",
    "    print(\"\\n===========================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best performing model is XGBRegressor, but Lasso does relatively well, which we can use if we need a more interpretable/simpler model. For our case, let's just use XGBRegressor since we care more of predictive power. Let's tune the XGBoost model for our problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets evaluate our model on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE:  4.876455355354596 %\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "model = xgb.fit(X_train_sparse, y_train, verbose=True)\n",
    "y_pred = xgb.predict(X_test_sparse)\n",
    "print(\"MAPE: \", MAPE(y_test, y_pred)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on Holdout Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the best model above, we now predict the holdout set for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051544797524904894\n"
     ]
    }
   ],
   "source": [
    "#refitting tfidf with full data set\n",
    "X_hold = X.loc[X.data_type == \"hold\"].drop(\"data_type\", axis = 1)\n",
    "\n",
    "X_train_total = X.loc[X.data_type == \"training\"].drop(\"data_type\", axis = 1)\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "X_train_total_sparse = vect.fit_transform(X_train_total.Description)\n",
    "X_hold_sparse = vect.transform(X_hold.Description)\n",
    "\n",
    "X_hold.drop(['Description', \"Created\"], axis = 1, inplace = True)\n",
    "\n",
    "for feature in X_train.columns:\n",
    "    X_train_total_sparse = hstack((X_train_total_sparse, np.array(X_train_total[feature]).reshape(-1,1)))\n",
    "    X_hold_sparse = hstack((X_hold_sparse, np.array(X_hold[feature]).reshape(-1,1)))\n",
    "\n",
    "#refitting lasso on full data set    \n",
    "l = Lasso(alpha = 10).fit(X_train_total_sparse, Y)\n",
    "\n",
    "#double checking this was done correctly\n",
    "print(sum(abs((Y - l.predict(X_train_total_sparse)) / Y))/len(Y))\n",
    "\n",
    "\n",
    "df_hold.drop('data_type', axis = 1, inplace = True)\n",
    "df_hold.Engagements = l.predict(X_hold_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hold.to_csv(\"holdout_set_Columbia.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
